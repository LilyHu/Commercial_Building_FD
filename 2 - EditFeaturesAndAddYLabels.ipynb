{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertRelevantToOnOffRemoveUncommonBAS(df_orig):\n",
    "    df = df_orig.copy()\n",
    "    # Convert speed to OnOff\n",
    "    df.loc[df['GP_1.y']>0.05, 'GP_1.y'] = 1\n",
    "    df.loc[df['GP_1.y']<=0.05, 'GP_1.y'] = 0\n",
    "    df.loc[df['GP2.y']>0.05, 'GP2.y'] = 1\n",
    "    df.loc[df['GP2.y']<=0.05, 'GP2.y'] = 0\n",
    "    df.loc[df['GP_20.y']>0.05, 'GP_20.y'] = 1\n",
    "    df.loc[df['GP_20.y']<=0.05, 'GP_20.y'] = 0\n",
    "    df.loc[df['GP4.N_actual']>=1, 'GP4.N_actual'] = 1\n",
    "    df.loc[df['GP4.N_actual']<1, 'GP4.N_actual'] = 0\n",
    "    df.loc[df['GP_5.y']>0.05, 'GP_5.y'] = 1\n",
    "    df.loc[df['GP_5.y']<=0.05, 'GP_5.y'] = 0\n",
    "    df.loc[df['GP6.y']>0.05, 'GP6.y'] = 1\n",
    "    df.loc[df['GP6.y']<=0.05, 'GP6.y'] = 0\n",
    "    df.loc[df['GP_21.y']>0.05, 'GP_21.y'] = 1\n",
    "    df.loc[df['GP_21.y']<=0.05, 'GP_21.y'] = 0\n",
    "    \n",
    "    # calculate the differential pressure of the second loop\n",
    "    df['secloopdp'] = df['senRelPre.port_a.p'] - df['senRelPre.port_b.p']\n",
    "    # remove the pressures\n",
    "    df = df.drop('senRelPre.port_a.p', 1)\n",
    "    df = df.drop('senRelPre.port_b.p', 1)\n",
    "    \n",
    "    # Drop other values identified as not being common BAS points\n",
    "    df = df.drop('ARU_1.dp2', 1)\n",
    "    #df = df.drop('VOut3.V_flow', 1)\n",
    "    df = df.drop('ARU_1.dp1', 1)\n",
    "    #df = df.drop('VOut7.V_flow', 1)\n",
    "    \n",
    "    df = df.drop('ARU_2.dp2', 1)\n",
    "    #df = df.drop('VOut2.V_flow', 1)\n",
    "    df = df.drop('ARU_2.dp1', 1)\n",
    "    #df = df.drop('VOut6.V_flow', 1)\n",
    "    \n",
    "    df = df.drop('ARU_3.dp2', 1)\n",
    "    #df = df.drop('VOut1.V_flow', 1)\n",
    "    df = df.drop('ARU_3.dp1', 1)\n",
    "    #df = df.drop('VOut5.V_flow', 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_p_files = os.listdir('../Data/MolecularFoundryPickleFiles_1-cleaned-but-units-unconverted')\n",
    "\n",
    "# For the output directory\n",
    "if not os.path.exists('../Data/MolecularFoundryPickleFiles_2-cleaned-units_converted'):\n",
    "    os.makedirs('../Data/MolecularFoundryPickleFiles_2-cleaned-units_converted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for input_file in input_p_files:\n",
    "    path = os.path.join('../Data/MolecularFoundryPickleFiles_1-cleaned-but-units-unconverted', input_file)\n",
    "    df =  pd.read_pickle(path)\n",
    "    df = convertRelevantToOnOffRemoveUncommonBAS(df)\n",
    "    new_path = os.path.join('../Data/MolecularFoundryPickleFiles_2-cleaned-units_converted', input_file)\n",
    "    df.to_pickle(new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create y labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Given a pandas series (which can be a column from a dataframe), great a label pandas series when the pandas series is ON\n",
    "'''\n",
    "def labelWhenOn(pd_series):\n",
    "    labels = pd.Series(index=pd_series.index, data=0)\n",
    "    labels[pd_series>0] = 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the important column name for each filename\n",
    "filename_seriesname_dict = {}\n",
    "filename_seriesname_dict['ARU1_max75min1.p'] = 'ARU_1.on'\n",
    "filename_seriesname_dict['ARU2_max75min1.p'] = 'ARU_2.on'\n",
    "filename_seriesname_dict['ARU3_max75min1.p'] = 'ARU_3.on'\n",
    "filename_seriesname_dict['coolingtower1_efficiency75percent.p'] = 'CT01.y'\n",
    "filename_seriesname_dict['coolingtower2_efficiency75percent.p'] = 'CT02.y'\n",
    "filename_seriesname_dict['GP1_efficiencyx75percent.p'] = 'GP_1.y'\n",
    "filename_seriesname_dict['GP20_efficiencyx75percent.p'] = 'GP_20.y'\n",
    "filename_seriesname_dict['GP21_efficiencyx75percent.p'] = 'GP_21.y'\n",
    "filename_seriesname_dict['GP2_efficiencyx75percent.p'] = 'GP2.y'\n",
    "filename_seriesname_dict['GP4_efficiencyx75percent.p'] = 'GP4.P'\n",
    "filename_seriesname_dict['GP5_efficiencyx75percent.p'] = 'GP_5.y'\n",
    "filename_seriesname_dict['GP6_efficiencyx75percent.p'] = 'GP6.y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = '../Data/MolecularFoundryPickleFiles_1-cleaned-but-units-unconverted'\n",
    "input_p_files = os.listdir(directory)\n",
    "for filename in input_p_files:\n",
    "    df = pd.read_pickle(os.path.join(directory, filename))\n",
    "    if filename in filename_seriesname_dict:\n",
    "        series_name = filename_seriesname_dict[filename]\n",
    "        labels = labelWhenOn(df[series_name])\n",
    "        labels.to_pickle(os.path.splitext(filename)[0]+'-label.p')\n",
    "\n",
    "df = pd.read_pickle(os.path.join(directory, 'no_faults.p'))\n",
    "labels = pd.Series(index=df.index, data=0)\n",
    "labels.to_pickle('no_faults-label.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create New Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DictMaxOfValues(orig_dict):\n",
    "    new_dict = {}\n",
    "    for key, value in orig_dict.items():\n",
    "        new_dict[key] = max(value)\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mergeDicts(a,b):\n",
    "    new_dict = {}\n",
    "    for key, value in a.items():\n",
    "        if type(value) != list:\n",
    "            value = [value]\n",
    "        new_dict[key] = value\n",
    "    for key, value in b.items():\n",
    "        if type(value) != list:\n",
    "            value = [value]\n",
    "        \n",
    "        if key in new_dict:\n",
    "            new_dict[key].extend(value)\n",
    "        else:\n",
    "            new_dict[key] = value\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "aic = pickle.load(open('wt_aic_order_dict', 'rb'))\n",
    "bic = pickle.load(open('wt_bic_order_dict', 'rb'))\n",
    "merged_dict = mergeDicts(aic, bic)\n",
    "order_dict = DictMaxOfValues(merged_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Creates lag dataframe\n",
    "Input:\n",
    "    df                 dataframe \n",
    "    order_dict         dict of {df.column name : number of lags}\n",
    "\n",
    "Returns:\n",
    "    lagged_features     dataframe with only the indices that have full rows\n",
    "'''\n",
    "def create_lagged_features(df, order_dict):\n",
    "\n",
    "    lagged_features = pd.DataFrame(index=df.index)\n",
    "\n",
    "    for key, n in order_dict.items():\n",
    "        if n > 0:\n",
    "            lags_for_one_variable = CreateLagsForOnePDSeries(df[key], key, n)\n",
    "            lagged_features = pd.concat([lagged_features, lags_for_one_variable], axis=1, join='inner')\n",
    "    \n",
    "    return lagged_features\n",
    "    \n",
    "    \n",
    "'''\n",
    "Creates lags for one pandas series\n",
    "Input:\n",
    "    pd_series          pandas.Series\n",
    "    name               str name of the pandas.Series\n",
    "    num_lags           int number of lags to calculate\n",
    "'''\n",
    "def CreateLagsForOnePDSeries(pd_series, name, num_lags):\n",
    "    lagged_variables = pd.DataFrame(index=pd_series.index)\n",
    "    for lag in range(1, num_lags+1):\n",
    "        temp_lags = pd.DataFrame(index=pd_series.index, data=pd_series.values, columns=[name + '_t-' + str(lag)])\n",
    "        time_to_add = str(lag*10) + 'min'\n",
    "        temp_lags.index = pd_series.index + pd.Timedelta(time_to_add)\n",
    "        lagged_variables = pd.concat([lagged_variables, temp_lags], axis=1, join='inner')\n",
    "    return lagged_variables\n",
    "\n",
    "\n",
    "def create_mean_std_features(df, order_dict):\n",
    "    \"\"\"\n",
    "    Calculate the 2hr mean and standard deviation for df\n",
    "    \"\"\"\n",
    "    mean_std_features = pd.DataFrame(index=df.index)\n",
    "\n",
    "    for key, n in order_dict.items():\n",
    "        if n == 0:\n",
    "            n = 6\n",
    "        print('Calculating Mean for %s \\n' % key)\n",
    "        mean_for_one_variable = calculateSlidingMeanForSeries(df[key], n)\n",
    "        mean_for_one_variable = pd.DataFrame(index=mean_for_one_variable.index, data=mean_for_one_variable.values, columns=[key + '_mean'])\n",
    "        print('Calculating Std for %s \\n' % key)\n",
    "        std_for_one_variable = calculateSlidingStdForSeries(df[key], n)\n",
    "        std_for_one_variable = pd.DataFrame(index=std_for_one_variable.index, data=std_for_one_variable.values, columns=[key + '_std'])\n",
    "        mean_std_features = pd.concat([mean_std_features, mean_for_one_variable, std_for_one_variable], axis=1, join='inner')    \n",
    "    return  mean_std_features\n",
    "    \n",
    "\n",
    "'''\n",
    "Given a series, returns a series\n",
    "'''    \n",
    "def calculateSlidingMeanForSeries(pd_series, window_size):\n",
    "    # Make a temporary new dataframe\n",
    "    temp_features = pd_series.copy()\n",
    "    temp_features[:] = np.nan\n",
    "    time_to_add = str(window_size*10) + 'min'\n",
    "    for i in range(window_size-1, len(pd_series)):\n",
    "        time = pd_series.index[i]\n",
    "        temp_features.iloc[i] = pd_series.loc[time-pd.Timedelta(time_to_add):time].mean(axis=0)\n",
    "    return temp_features\n",
    "\n",
    "'''\n",
    "Given a series, returns a series\n",
    "''' \n",
    "def calculateSlidingStdForSeries(pd_series, window_size):\n",
    "    # Make a temporary new dataframe\n",
    "    temp_features = pd_series.copy()\n",
    "    temp_features[:] = np.nan\n",
    "    time_to_add = str(window_size*10) + 'min'\n",
    "    for i in range(window_size-1, len(pd_series)):\n",
    "        time = pd_series.index[i]\n",
    "        temp_features.iloc[i] = pd_series.loc[time-pd.Timedelta(time_to_add):time].std()   \n",
    "    return temp_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../Data/PickleFiles/orig_and_eng.p')\n",
    "lags = create_lagged_features(df, order_dict) # Create lags\n",
    "meanstd = create_mean_std_features(df, order_dict)\n",
    "meanstd.to_pickle('../Data/PickleFiles/mean_std_new_features.p')\n",
    "new_df = pd.concat([df, lags, meanstd], axis=1, join='inner') # Concatenate with the original data\n",
    "new_df.dropna(inplace=True)\n",
    "new_df.to_pickle('../Data/PickleFiles/orig_eng_mean_std_lags.p')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
